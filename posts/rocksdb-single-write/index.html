<!doctype html><html class="not-ready text-sm lg:text-base" style=--bg:#faf6f1 lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>RocksDB WAL 单写者写入优化 - 正小歪 BLOG</title><meta name=theme-color><meta name=description content="背景 由于 WAL 需要有序写入，但是 RocksDB 的 DBImpl::Write 本身又是多线程并发，所以在调用 Write 时候有一个先后顺序的问题，一般的解决办法就是写入一个队列中，然后不断的从队列读取写入 WAL 中，这种方式比较低效，LevelDB 优化成把多个 Write 合并成一个 WriteBatch 写入 WAL 中，其他线程等待完成，RocksDB 使用自旋和自适应的 short-wait 进步一优化，使得 WAL 的写入效率进一步提高。
LevelDB 实现 LevelDB 对这种情况做了一个简单优化，每次只有队头是真正的处理线程，对头会把队列中的其他待写入的内容合并成一个 WriteBatch 一次性写入 WAL 中，同时非对头线程会被 pthread_cond_wait 阻塞住，等待对头线程完成。
MutexLock l(&mutex_); writers_.push_back(&w); while (!w.done && &w != writers_.front()) { w.cv.Wait(); } if (w.done) { return w.status; } 完成了以后非队头只需要判断一下状态就可以返回了，这么一看确实提升了不少效率，每次 IO 对一个单点写入的来说都是比较重的操作，合并成一次写入极大解决的耗在 IO 的时间。
pthread_cond_wait 存在的问题 虽然解决了 IO 的耗时，但是非队头线程会在各自的线程中 pthread_cond_wait 等待对头完成。几乎当前主流平台的 condition variable 都有虚假唤醒 （Spurious wakeup） 的问题，同样基于 futex 实现的 pthread_cond_wait 也有这个问题。"><meta name=author content><link rel="preload stylesheet" as=style href=http://hexiangyu.me/main.min.css><script defer src=http://hexiangyu.me/highlight.min.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=preload as=image href=http://hexiangyu.me/theme.png><link rel=icon href=http://hexiangyu.me/favicon.ico><link rel=apple-touch-icon href=http://hexiangyu.me/apple-touch-icon.png><meta name=generator content="Hugo 0.105.0"><meta property="og:title" content="RocksDB WAL 单写者写入优化"><meta property="og:description" content="背景 由于 WAL 需要有序写入，但是 RocksDB 的 DBImpl::Write 本身又是多线程并发，所以在调用 Write 时候有一个先后顺序的问题，一般的解决办法就是写入一个队列中，然后不断的从队列读取写入 WAL 中，这种方式比较低效，LevelDB 优化成把多个 Write 合并成一个 WriteBatch 写入 WAL 中，其他线程等待完成，RocksDB 使用自旋和自适应的 short-wait 进步一优化，使得 WAL 的写入效率进一步提高。
LevelDB 实现 LevelDB 对这种情况做了一个简单优化，每次只有队头是真正的处理线程，对头会把队列中的其他待写入的内容合并成一个 WriteBatch 一次性写入 WAL 中，同时非对头线程会被 pthread_cond_wait 阻塞住，等待对头线程完成。
MutexLock l(&mutex_); writers_.push_back(&w); while (!w.done && &w != writers_.front()) { w.cv.Wait(); } if (w.done) { return w.status; } 完成了以后非队头只需要判断一下状态就可以返回了，这么一看确实提升了不少效率，每次 IO 对一个单点写入的来说都是比较重的操作，合并成一次写入极大解决的耗在 IO 的时间。
pthread_cond_wait 存在的问题 虽然解决了 IO 的耗时，但是非队头线程会在各自的线程中 pthread_cond_wait 等待对头完成。几乎当前主流平台的 condition variable 都有虚假唤醒 （Spurious wakeup） 的问题，同样基于 futex 实现的 pthread_cond_wait 也有这个问题。"><meta property="og:type" content="article"><meta property="og:url" content="http://hexiangyu.me/posts/rocksdb-single-write/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-09-06T08:00:44+08:00"><meta property="article:modified_time" content="2022-09-06T08:00:44+08:00"><meta itemprop=name content="RocksDB WAL 单写者写入优化"><meta itemprop=description content="背景 由于 WAL 需要有序写入，但是 RocksDB 的 DBImpl::Write 本身又是多线程并发，所以在调用 Write 时候有一个先后顺序的问题，一般的解决办法就是写入一个队列中，然后不断的从队列读取写入 WAL 中，这种方式比较低效，LevelDB 优化成把多个 Write 合并成一个 WriteBatch 写入 WAL 中，其他线程等待完成，RocksDB 使用自旋和自适应的 short-wait 进步一优化，使得 WAL 的写入效率进一步提高。
LevelDB 实现 LevelDB 对这种情况做了一个简单优化，每次只有队头是真正的处理线程，对头会把队列中的其他待写入的内容合并成一个 WriteBatch 一次性写入 WAL 中，同时非对头线程会被 pthread_cond_wait 阻塞住，等待对头线程完成。
MutexLock l(&mutex_); writers_.push_back(&w); while (!w.done && &w != writers_.front()) { w.cv.Wait(); } if (w.done) { return w.status; } 完成了以后非队头只需要判断一下状态就可以返回了，这么一看确实提升了不少效率，每次 IO 对一个单点写入的来说都是比较重的操作，合并成一次写入极大解决的耗在 IO 的时间。
pthread_cond_wait 存在的问题 虽然解决了 IO 的耗时，但是非队头线程会在各自的线程中 pthread_cond_wait 等待对头完成。几乎当前主流平台的 condition variable 都有虚假唤醒 （Spurious wakeup） 的问题，同样基于 futex 实现的 pthread_cond_wait 也有这个问题。"><meta itemprop=datePublished content="2022-09-06T08:00:44+08:00"><meta itemprop=dateModified content="2022-09-06T08:00:44+08:00"><meta itemprop=wordCount content="393"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="RocksDB WAL 单写者写入优化"><meta name=twitter:description content="背景 由于 WAL 需要有序写入，但是 RocksDB 的 DBImpl::Write 本身又是多线程并发，所以在调用 Write 时候有一个先后顺序的问题，一般的解决办法就是写入一个队列中，然后不断的从队列读取写入 WAL 中，这种方式比较低效，LevelDB 优化成把多个 Write 合并成一个 WriteBatch 写入 WAL 中，其他线程等待完成，RocksDB 使用自旋和自适应的 short-wait 进步一优化，使得 WAL 的写入效率进一步提高。
LevelDB 实现 LevelDB 对这种情况做了一个简单优化，每次只有队头是真正的处理线程，对头会把队列中的其他待写入的内容合并成一个 WriteBatch 一次性写入 WAL 中，同时非对头线程会被 pthread_cond_wait 阻塞住，等待对头线程完成。
MutexLock l(&mutex_); writers_.push_back(&w); while (!w.done && &w != writers_.front()) { w.cv.Wait(); } if (w.done) { return w.status; } 完成了以后非队头只需要判断一下状态就可以返回了，这么一看确实提升了不少效率，每次 IO 对一个单点写入的来说都是比较重的操作，合并成一次写入极大解决的耗在 IO 的时间。
pthread_cond_wait 存在的问题 虽然解决了 IO 的耗时，但是非队头线程会在各自的线程中 pthread_cond_wait 等待对头完成。几乎当前主流平台的 condition variable 都有虚假唤醒 （Spurious wakeup） 的问题，同样基于 futex 实现的 pthread_cond_wait 也有这个问题。"></head><body class="text-black duration-200 ease-out dark:text-white"><header class="mx-auto flex h-[5rem] max-w-3xl px-8 lg:justify-center"><div class="relative z-50 mr-auto flex items-center"><a class="-translate-x-[1px] -translate-y-0.5 text-3xl font-bold" href=http://hexiangyu.me/>正小歪 BLOG</a>
<a class="btn-dark ml-6 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.png)_left_center/_auto_theme('spacing.6')_no-repeat] [transition:_background-position_0.4s_steps(5)] dark:[background-position:right]"></a></div><a class="btn-menu relative z-50 -mr-8 flex h-[5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden"></a>
<script>const htmlClass=document.documentElement.classList;setTimeout(()=>{htmlClass.remove("not-ready")},10);const btnMenu=document.querySelector(".btn-menu");btnMenu.addEventListener("click",()=>{htmlClass.toggle("open")});const metaTheme=document.querySelector('meta[name="theme-color"]'),lightBg=`"#faf6f1"`.replace(/"/g,""),setDark=e=>{metaTheme.setAttribute("content",e?"#000":lightBg),htmlClass[e?"add":"remove"]("dark"),localStorage.setItem("dark",e)},darkScheme=window.matchMedia("(prefers-color-scheme: dark)"),darkVal=localStorage.getItem("dark");setDark(darkVal?darkVal==="true":darkScheme.matches),darkScheme.addEventListener("change",e=>{setDark(e.matches)});const btnDark=document.querySelector(".btn-dark");btnDark.addEventListener("click",()=>{setDark(localStorage.getItem("dark")!=="true")})</script><div class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"></div></header><main class="prose prose-neutral relative mx-auto min-h-[calc(100%-10rem)] max-w-3xl px-8 pt-20 pb-32 dark:prose-invert"><article><header class=mb-20><h1 class="!my-0 pb-2.5">RocksDB WAL 单写者写入优化</h1><div class="text-sm opacity-60"><time>Sep 6, 2022</time></div></header><section><h1 id=背景>背景</h1><p>由于 WAL 需要有序写入，但是 RocksDB 的 DBImpl::Write 本身又是多线程并发，所以在调用 Write 时候有一个先后顺序的问题，一般的解决办法就是写入一个队列中，然后不断的从队列读取写入 WAL 中，这种方式比较低效，LevelDB 优化成把多个 Write 合并成一个 WriteBatch 写入 WAL 中，其他线程等待完成，RocksDB 使用自旋和自适应的 short-wait 进步一优化，使得 WAL 的写入效率进一步提高。</p><h1 id=leveldb-实现>LevelDB 实现</h1><p>LevelDB 对这种情况做了一个简单优化，每次只有队头是真正的处理线程，对头会把队列中的其他待写入的内容合并成一个 WriteBatch 一次性写入 WAL 中，同时非对头线程会被 pthread_cond_wait 阻塞住，等待对头线程完成。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=display:flex><span>MutexLock <span style=color:#a6e22e>l</span>(<span style=color:#f92672>&amp;</span>mutex_);
</span></span><span style=display:flex><span>writers_.push_back(<span style=color:#f92672>&amp;</span>w);
</span></span><span style=display:flex><span><span style=color:#66d9ef>while</span> (<span style=color:#f92672>!</span>w.done <span style=color:#f92672>&amp;&amp;</span> <span style=color:#f92672>&amp;</span>w <span style=color:#f92672>!=</span> writers_.front()) {
</span></span><span style=display:flex><span>  w.cv.Wait();
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> (w.done) {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> w.status;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>完成了以后非队头只需要判断一下状态就可以返回了，这么一看确实提升了不少效率，每次 IO 对一个单点写入的来说都是比较重的操作，合并成一次写入极大解决的耗在 IO 的时间。</p><h1 id=pthread_cond_wait-存在的问题>pthread_cond_wait 存在的问题</h1><p>虽然解决了 IO 的耗时，但是非队头线程会在各自的线程中 pthread_cond_wait 等待对头完成。几乎当前主流平台的 condition variable 都有虚假唤醒 （<a href=https://en.wikipedia.org/wiki/Spurious_wakeup>Spurious wakeup</a>） 的问题，同样基于 futex 实现的 pthread_cond_wait 也有这个问题。</p><p>RocksDB 的 Contributor 测出从 FUTEX_WAIT 到 FUTEX_WAKE 的平均时间大约是 10 微妙左右，而且这个过程还没算上多次的虚假唤醒和上下文切换的时间，如果竞争激烈这个过程耗时还会增加，这对于非队头写入的等待线程来说会额外消耗不少的等待时间。</p><blockquote><p>为什么会有虚假唤醒没有找到准确的答案，一种比较靠谱的说法就是如果一次唤醒过多的等待者，不如一口气全部唤醒，基本上 condition variable 的 wait 都被要求有额外的退出等待条件。</p></blockquote><h1 id=rocksdb-实现>RocksDB 实现</h1><p>分析一下 pthread_cond_wait 有存在两个问题，锁唤醒需要时间和上下文切换需要时间。RocksDB 从这两方面入手分别使用 Busy Loop 解决锁和上下文切换的问题，如果 Busy Loop 解决不了就退化成 short-wait 解决锁的问题，最后的最后还是解决不了那就还是老方法直接等待。</p><h2 id=busy-loop>Busy Loop</h2><p>刚进 <code>AwaitState</code> 函数就先阻塞 1 微妙，这里的 200 次是根据 Contributor 测出来的大致时间，跑在不同的机器上这个时间会有偏差。这里使用 <code>port::AsmVolatilePause()</code> 暂停当前线程，根据参考 1 中可以得知这段汇编一般使用在 spin-wait-loop 中，可以避免内存重排从而提高性能。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-C++ data-lang=C++><span style=display:flex><span><span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>uint32_t</span> tries <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; tries <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>200</span>; <span style=color:#f92672>++</span>tries) {
</span></span><span style=display:flex><span>  state <span style=color:#f92672>=</span> w<span style=color:#f92672>-&gt;</span>state.load(std<span style=color:#f92672>::</span>memory_order_acquire);
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> ((state <span style=color:#f92672>&amp;</span> goal_mask) <span style=color:#f92672>!=</span> <span style=color:#ae81ff>0</span>) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> state;
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>  port<span style=color:#f92672>::</span>AsmVolatilePause();
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>每次循环都会检查一次状态是否完成，然后暂停一下再次检查。这个的手法就是利用阻塞行为不断的检查状态，这么做可以避免锁的问题和上下文切换，带来的副作用就是会增加 CPU 的使用率，利用较小的代价完成较重的操作。</p><h2 id=short-waits>Short-Waits</h2><p>在第一步 Busy Loop 中很难保证所有的请求都被处理完成，就意味着需要更多的时间。第一步已经阻塞了线程调度，所以在第二步中需要使用 <code>std::this_thread::yield()</code> 主动让出线程的控制权，此时会发生上下文切换，但是不会有锁唤醒的问题。</p><p>实现上如果打开了参数 <code>max_yield_usec_</code> 就是 100，也就是说 short-wait 最多存在 100 微妙。同时第一次是否启用 short-wait 和 update_ctx 有关，第一次的 yield_credit 是 0，但是 update_ctx 有 1/256 之一为 true 依赖可以启用。如果再次拿回控制权时间大于 3 微妙被认为是耗时较多，3 次耗时较多以后会直接退出 short-wait。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-C++ data-lang=C++><span style=display:flex><span><span style=color:#66d9ef>if</span> (max_yield_usec_ <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0</span>) {
</span></span><span style=display:flex><span>  <span style=color:#75715e>// 1/256
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>  update_ctx <span style=color:#f92672>=</span> Random<span style=color:#f92672>::</span>GetTLSInstance()<span style=color:#f92672>-&gt;</span>OneIn(sampling_base);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> (update_ctx <span style=color:#f92672>||</span> yield_credit.load(std<span style=color:#f92672>::</span>memory_order_relaxed) <span style=color:#f92672>&gt;=</span> <span style=color:#ae81ff>0</span>) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>auto</span> spin_begin <span style=color:#f92672>=</span> std<span style=color:#f92672>::</span>chrono<span style=color:#f92672>::</span>steady_clock<span style=color:#f92672>::</span>now();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    size_t slow_yield_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>auto</span> iter_begin <span style=color:#f92672>=</span> spin_begin;
</span></span><span style=display:flex><span>    <span style=color:#75715e>// 最长时间不超过 max_yield_usec_
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>while</span> ((iter_begin <span style=color:#f92672>-</span> spin_begin) <span style=color:#f92672>&lt;=</span>
</span></span><span style=display:flex><span>           std<span style=color:#f92672>::</span>chrono<span style=color:#f92672>::</span>microseconds(max_yield_usec_)) {
</span></span><span style=display:flex><span>      <span style=color:#75715e>// 让出线程使用权，阻塞在这里，再次获取控制权从这里开始
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>      std<span style=color:#f92672>::</span>this_thread<span style=color:#f92672>::</span>yield(); 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      state <span style=color:#f92672>=</span> w<span style=color:#f92672>-&gt;</span>state.load(std<span style=color:#f92672>::</span>memory_order_acquire);
</span></span><span style=display:flex><span>      <span style=color:#66d9ef>if</span> ((state <span style=color:#f92672>&amp;</span> goal_mask) <span style=color:#f92672>!=</span> <span style=color:#ae81ff>0</span>) {
</span></span><span style=display:flex><span>        <span style=color:#75715e>// success
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#75715e>// would_spin_again 会增加 yield_credit
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        would_spin_again <span style=color:#f92672>=</span> true;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>break</span>;
</span></span><span style=display:flex><span>      }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      <span style=color:#66d9ef>auto</span> now <span style=color:#f92672>=</span> std<span style=color:#f92672>::</span>chrono<span style=color:#f92672>::</span>steady_clock<span style=color:#f92672>::</span>now();
</span></span><span style=display:flex><span>      <span style=color:#66d9ef>if</span> (now <span style=color:#f92672>==</span> iter_begin <span style=color:#f92672>||</span>
</span></span><span style=display:flex><span>          now <span style=color:#f92672>-</span> iter_begin <span style=color:#f92672>&gt;=</span> std<span style=color:#f92672>::</span>chrono<span style=color:#f92672>::</span>microseconds(slow_yield_usec_)) {
</span></span><span style=display:flex><span>        <span style=color:#f92672>++</span>slow_yield_count;
</span></span><span style=display:flex><span>        <span style=color:#75715e>// kMaxSlowYieldsWhileSpinning = 3
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#66d9ef>if</span> (slow_yield_count <span style=color:#f92672>&gt;=</span> kMaxSlowYieldsWhileSpinning) {
</span></span><span style=display:flex><span>          update_ctx <span style=color:#f92672>=</span> true;
</span></span><span style=display:flex><span>          <span style=color:#66d9ef>break</span>;
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>      }
</span></span><span style=display:flex><span>      iter_begin <span style=color:#f92672>=</span> now;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>如果耗时真的就是比较长，short-wait 会导致超过 100 微妙失效，反而有了副作用，RocksDB 巧妙的实现为自适应的。下面的代码可以看出 yield_credit 被更新是条件是 update_ctx 为 true，update_ctx 只有在 slow_yield_count >= 3 时候或者 1/256 才会被设置为 true ，此时 yield_credit 才会更新。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-C++ data-lang=C++><span style=display:flex><span><span style=color:#66d9ef>if</span> (update_ctx) {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>auto</span> v <span style=color:#f92672>=</span> yield_credit.load(std<span style=color:#f92672>::</span>memory_order_relaxed);
</span></span><span style=display:flex><span>  v <span style=color:#f92672>=</span> v <span style=color:#f92672>-</span> (v <span style=color:#f92672>/</span> <span style=color:#ae81ff>1024</span>) <span style=color:#f92672>+</span> (would_spin_again <span style=color:#f92672>?</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>:</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>) <span style=color:#f92672>*</span> <span style=color:#ae81ff>131072</span>;
</span></span><span style=display:flex><span>  yield_credit.store(v, std<span style=color:#f92672>::</span>memory_order_relaxed);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>yield_credit 是一个成员变量，如果 short-wait 成功会增加 yield_credit 失败会减少 yield_credit，即使 yield_credit 为负数，还是会有 1/256 几率走 short-wait。</p><h2 id=long-waits>Long-Waits</h2><p>前面两种优化都不起作用的话，最后只能进行等锁了。short-wait 失败次数过多，也意味着耗时真的比较长，不如直接进行 long-wait 流程，等待锁的唤醒。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-C++ data-lang=C++><span style=display:flex><span><span style=color:#66d9ef>uint8_t</span> WriteThread<span style=color:#f92672>::</span>BlockingAwaitState(Writer<span style=color:#f92672>*</span> w, <span style=color:#66d9ef>uint8_t</span> goal_mask) {
</span></span><span style=display:flex><span>  w<span style=color:#f92672>-&gt;</span>CreateMutex();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>auto</span> state <span style=color:#f92672>=</span> w<span style=color:#f92672>-&gt;</span>state.load(std<span style=color:#f92672>::</span>memory_order_acquire);
</span></span><span style=display:flex><span>  assert(state <span style=color:#f92672>!=</span> STATE_LOCKED_WAITING);
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>if</span> ((state <span style=color:#f92672>&amp;</span> goal_mask) <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span> <span style=color:#f92672>&amp;&amp;</span>
</span></span><span style=display:flex><span>      w<span style=color:#f92672>-&gt;</span>state.compare_exchange_strong(state, STATE_LOCKED_WAITING)) {
</span></span><span style=display:flex><span>    std<span style=color:#f92672>::</span>unique_lock<span style=color:#f92672>&lt;</span>std<span style=color:#f92672>::</span>mutex<span style=color:#f92672>&gt;</span> guard(w<span style=color:#f92672>-&gt;</span>StateMutex());
</span></span><span style=display:flex><span>    w<span style=color:#f92672>-&gt;</span>StateCV().wait(guard, [w] {
</span></span><span style=display:flex><span>      <span style=color:#66d9ef>return</span> w<span style=color:#f92672>-&gt;</span>state.load(std<span style=color:#f92672>::</span>memory_order_relaxed) <span style=color:#f92672>!=</span> STATE_LOCKED_WAITING;
</span></span><span style=display:flex><span>    });
</span></span><span style=display:flex><span>    state <span style=color:#f92672>=</span> w<span style=color:#f92672>-&gt;</span>state.load(std<span style=color:#f92672>::</span>memory_order_relaxed);
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>  assert((state <span style=color:#f92672>&amp;</span> goal_mask) <span style=color:#f92672>!=</span> <span style=color:#ae81ff>0</span>);
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> state;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h1 id=参考>参考</h1><ol><li><p><a href=https://kernelmaker.github.io/Rocksdb_Study_1>https://kernelmaker.github.io/Rocksdb_Study_1</a></p></li><li><p><a href=http://mysql.taobao.org/monthly/2018/07/04/>http://mysql.taobao.org/monthly/2018/07/04/</a></p></li></ol></section><nav class="mt-24 flex rounded-lg bg-black/[3%] text-lg dark:bg-white/[8%]"><a class="flex w-1/2 items-center p-6 pr-3 no-underline" href=http://hexiangyu.me/posts/cmu-15-445-tree-indexes1/><span class=mr-1.5>←</span><span>CMU 15-445/645 Lecture 6: Trees Indexes I</span></a>
<a class="ml-auto flex w-1/2 items-center justify-end p-6 pl-3 no-underline" href=http://hexiangyu.me/posts/mvcc-concepts-and-hbase-impl/><span>MVCC Concepts and HBase Implementation</span><span class=ml-1.5>→</span></a></nav></article></main><footer class="opaco mx-auto flex h-[5rem] max-w-3xl items-center px-8 text-[0.9em] opacity-60"><div class=mr-auto>&copy; 2022
<a class=link href=http://hexiangyu.me/>正小歪 BLOG</a></div><a class="link mx-6" href=https://gohugo.io/ rel=noopener target=_blank>Powered by Hugo️️</a>️
<a class=link href=https://github.com/nanxiaobei/hugo-paper rel=noopener target=_blank>▷ Paper 6</a></footer></body></html>